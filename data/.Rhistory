y = 'Life Expectancy (Years)')
life_lm_inter <- lm(LifeExp ~ PPGDP +
africaGroup +
oecdGroup +
PPGDP:Group,
data = salary)
life_lm_inter <- lm(LifeExp ~ PPGDP +
africaGroup +
oecdGroup +
PPGDP:Group,
data = life)
summary(life_lm_inter)
life_lm_inter <- lm(LifeExp ~ PPGDP +
africaGroup +
oecdGroup +
PPGDP:africaGroup +
PPGDP:oecdGroup,
data = life)
summary(life_lm_inter)
anova(life_lm_overparm, life_lm_inter)
ggplot(life) +
geom_point(mapping = aes(x = PPGDP,
y = LifeExp,
color = Group)) +
geom_line(mapping = aes(x = PPGDP,
y = predict(life_lm_inter),
color = Group)) +
theme(aspect.ratio = 1) +
labs(title = 'PPGDP vs Life Expectancy Scatterplot (color by Group)',
x = 'Per Person GDP (Log Scale)',
y = 'Life Expectancy (Years)')
pbinom(54, 4, lower.tail = TRUE)
pnorm(q = 54, mean = 53, sd = .5, lower.tail = TRUE)
pnorm(q = 53, mean = 53, sd = .5, lower.tail = TRUE)
pnorm(q = 54, mean = 53, sd = .5, lower.tail = TRUE) - pnorm(q = 53, mean = 53, sd = .5, lower.tail = TRUE)
n_list <- c(1:25)
ideal_prob <- function(n_list) {
for(i in n_list) {
print(n_list[i])
}
}
ideal_prob()
ideal_prob()
ideal_prob <- function(list) {
for(i in n_list) {
print(list[i])
}
}
ideal_prob(n_list)
ideal_prob <- function(list) {
for(i in n_list) {
sd_i <- sqrt(1/n_list[i])
p_i <- pnorm(q = 54, mean = 53, sd = sd_i, lower.tail = TRUE)
print(p_i)
}
}
ideal_prob(n_list)
ideal_prob <- function(list) {
for(i in n_list) {
sd_i <- sqrt(1/n_list[i])
p_i <- pnorm(q = 54, mean = 53, sd = sd_i, lower.tail = TRUE)
print(c(n_list[i],p_i))
}
}
ideal_prob(n_list)
ideal_prob <- function(list) {
for(i in n_list) {
sd_i <- sqrt(1/n_list[i])
p_i <- pnorm(q = 54, mean = 53, sd = sd_i, lower.tail = TRUE)
print(c(lapply(n_list[i]),p_i))
}
}
ideal_prob(n_list)
ideal_prob <- function(list) {
for(i in n_list) {
sd_i <- sqrt(1/n_list[i])
p_i <- pnorm(q = 54, mean = 53, sd = sd_i, lower.tail = TRUE)
print(c(lapply(n_list[i], as.integer),p_i))
}
}
ideal_prob(n_list)
ideal_prob <- function(list) {
for(i in n_list) {
sd_i <- sqrt(1/n_list[i])
p_i <- pnorm(q = 54, mean = 53, sd = sd_i, lower.tail = TRUE)
print(p_i)
}
}
ideal_prob(n_list)
pnorm(q = 500, mean = 390, sd = 14.6969, lower.tail = TRUE)
pbern(x, prob = 0.6)
phat <- vector(0:n)/n
p = .6
n = 3
calc_binomzn <- function(p, n) {
}
calc_binomzn(p,n)
calc_binomzn <- function(p, n) {
phat <- vector(0:n)/n
zn <- (phat - p) / (sqrt((p(1-p))/n))
Fbin <- pbinom(n*p + sqrt(n*p*(1-p))*zn, n, p)
return(list(zn = zn, Fbin = Fbin))
}
n3
n3 <- calc_binomzn(.6, 3)
calc_binomzn <- function(p, n) {
phat <- c(0:n)/n
zn <- (phat - p) / (sqrt((p(1-p))/n))
Fbin <- pbinom(n*p + sqrt(n*p*(1-p))*zn, n, p)
return(list(zn = zn, Fbin = Fbin))
}
n3 <- calc_binomzn(.6, 3)
calc_binomzn <- function(p, n) {
phat <- c(0:n)/n
zn <- (phat - p) / (sqrt((p*(1-p))/n))
Fbin <- pbinom(n*p + sqrt(n*p*(1-p))*zn, n, p)
return(list(zn = zn, Fbin = Fbin))
}
n3 <- calc_binomzn(.6, 3)
n15 <- calc_binomzn(.6, 15)
n30 <- calc_binomzn(.6, 30)
n3
n15
n30
plot(n3$zn, n3$Fbin)
plot(n3$zn, n3$Fbin, type = 's')
plot(n3$zn, n3$Fbin, type = 's')
plot(n3$zn, n3$Fbin, type = 's')
plot(n3$zn, n3$Fbin, type = 's')
points(n15$zn, n15$Fbin, type = 's')
points(n30$zn, n30$Fbin, type = 's')
plot(n3$zn, n3$Fbin, type = 's')
points(n15$zn, n15$Fbin, type = 's')
points(n30$zn, n30$Fbin, type = 's')
curve(pnorm, from = -2, to = 1.5)
plot(n3$zn, n3$Fbin, type = 's')
points(n15$zn, n15$Fbin, type = 's')
points(n30$zn, n30$Fbin, type = 's')
curve(pnorm, from = -2, to = 1.5)
plot(n3$zn, n3$Fbin, type = 's')
points(n15$zn, n15$Fbin, type = 's')
points(n30$zn, n30$Fbin, type = 's')
points(curve(pnorm, from = -2, to = 1.5))
lines(pnorm, from = -2, to = 1.5)
lines(x, type = 's')
x_n <- seq(from = -3, to = 3)
pnorm(x_n, 0, 1)
x_n1 <- pnorm(x_n, 0, 1)
lines(x_n1, type = 's')
lines(x_n1, y = NULL, type = 's')
lines(x_n, x_n1, type = 's')
plot(n3$zn, n3$Fbin, type = 's')
x_n <- seq(-2:2)
x_n
x_n <- seq(-200:200)/50
x_n
points(x_n, pnorm(x_n, 0, 1), type = 's')
plot(n3$zn, n3$Fbin, type = 's')
points(n15$zn, n15$Fbin, type = 's')
points(n30$zn, n30$Fbin, type = 's')
points(x_n, pnorm(x_n, 0, 1), type = 's')
x_n <- seq(-200:200)
x_n
x_n <- seq(-2, 2, 0.001)
x_n
plot(n3$zn, n3$Fbin, type = 's')
points(n15$zn, n15$Fbin, type = 's')
points(n30$zn, n30$Fbin, type = 's')
points(x_n, pnorm(x_n, 0, 1), type = 's')
# load packages here
library(tidyverse)
# read in data
df <- read_csv('state_of_utah.csv')
head(df)
df['81-90'] <- df %>%
mutate(sum = rowSums(across(c(`1981`, `1982`, `1983`, `1984`, `1985`, `1986`, `1987`, `1988`, `1989`, `1990`))))
df %>%
mutate(sum = rowSums(across(c(`1981`, `1982`, `1983`, `1984`, `1985`, `1986`, `1987`, `1988`, `1989`, `1990`))))
df[,'81-90'] <- df[,54]
df[,54]
df[54]
df[, 54]
df[, 12]
df
df[,'81-90'] <- df %>%
mutate(sum = rowSums(across(c(`1981`, `1982`, `1983`, `1984`, `1985`, `1986`, `1987`, `1988`, `1989`, `1990`))))
df1 <- df %>%
mutate(sum = rowSums(across(c(`1981`, `1982`, `1983`, `1984`, `1985`, `1986`, `1987`, `1988`, `1989`, `1990`))))
df[,'81-90'] <- df1[, 54]
df
df2 <- df %>%
mutate(sum = rowSums(across(c(`1991`, `1992`, `1993`, `1994`, `1995`, `1996`, `1997`, `1998`, `1999`, `2000`))))
df[, '91-2000'] <- df2[, 54]
df
# load packages here
library(tidyverse)
# read in data
df <- read_csv('state_of_utah.csv')
# head(df)
df1 <- df %>%
mutate(sum = rowSums(across(c(`1981`, `1982`, `1983`, `1984`, `1985`, `1986`, `1987`, `1988`, `1989`, `1990`))))
df[,'81-90'] <- df1[, 54]
df2 <- df %>%
mutate(sum = rowSums(across(c(`1991`, `1992`, `1993`, `1994`, `1995`, `1996`, `1997`, `1998`, `1999`, `2000`))))
df[, '91-2000'] <- df2[, 54]
df3 <- df %>%
mutate(sum = rowSums(across(c(`2001`, `2002`, `2003`, `2004`, `2005`, `2006`, `2007`, `2008`, `2009`, `2010`))))
df[, '01-2010'] <- df3[, 54]
df4 <- df %>%
mutate(sum = rowSums(across(c(`2011`, `2012`, `2013`, `2014`, `2015`, `2016`, `2017`, `2018`, `2019`, `2020`))))
df[, '11-2020'] <- df2[, 54]
head(df)
# 1a
#define range
p = seq(0, 1, length=100)
#create plot of Beta distribution with shape parameters
plot(p, dbeta(p, 6, 4), type='l')
# 1d
qbeta(.025, 83, 27)
qbeta(.975, 83, 27)
#create plot of Beta distribution with shape parameters
plot1 <- plot(p, dbeta(p, 6, 4), type='l')
#create plot of Beta distribution with shape parameters
plot1 <- plot(p, dbeta(p, 6, 4), type='l')
# 1e
plot1
# 1e
plot(p, dbeta(p, 83, 27), type='l')
# 1e
plot(p, dbeta(p, 83, 27), type='l')
plot(p, dbeta(p, 83, 27), type='l')
abline(v = .7545)
abline(v = 0.670348, col="red", lwd=3, lty=2)
abline(v = 0.82998, col="red", lwd=3, lty=2)
# 2a
plot(p, dnorm(p, 15, sqrt(2.5)), type = 'l')
# 2a
p2 = seq(10, 20, length = 100)
plot(p2, dnorm(p, 15, sqrt(2.5)), type = 'l')
p2
plot(p2, dnorm(p, 15, sqrt(2.5)), type = 'l')
plot(p2, dnorm(p2, 15, sqrt(2.5)), type = 'l')
# 2d
qnorm(.025, 14.9358, 0.9682)
qnorm(.975, 14.9358, 0.9682)
plot(p2, dnorm(p2, 14.9358, 0.9682), type='l')
abline(v = .14.9358)
abline(v = 13.03816, col="red", lwd=3, lty=2)
abline(v = 16.83344, col="red", lwd=3, lty=2)
abline(v = .14.9358)
plot(p2, dnorm(p2, 14.9358, 0.9682), type='l')
abline(v = 14.9358)
abline(v = 13.03816, col="red", lwd=3, lty=2)
abline(v = 16.83344, col="red", lwd=3, lty=2)
# Question 1
t.test(x, conf.level = 0.88)
# Question 1
t.test(1584, conf.level = 0.99)
# Question 1
qt(.99, 19)
# Question 1
qt(.995, 19)
# Question 2
c(25.2,21.3,22.8,17,29.8,21,25.5,16,20.9,19.5)
# Question 2
sample1 <- c(25.2,21.3,22.8,17,29.8,21,25.5,16,20.9,19.5)
mean(sample1)
sd(sample1)
qt(.975, 9)
# Question 3
sample2 <- c(.53, .65, .46, .50, .37)
# L: Residuals vs. Fitted Values Plot
sample2_residvfit <- autoplot(sample2, which = 1, ncol = 1, nrow = 1) +
theme(aspect.ratio = 1)
library(tidyverse)
library(ggfortify)
# Check Normality Assumption
# Normal Probability Plot
#   "qq plot"
sample2_qq <- autoplot(sample2, which = 2, ncol = 1, nrow = 1) +
theme(aspect.ratio = 1)
sample2_qq
qqnorm(sample2)
qqnorm(sample2)
qqline(sample2)
qqline(sample2)
qqnorm(sample2)
qqnorm(sample2)
qqnorm(sample2)
qqline(sample2)
# Question 4
sample2 <- c(.53, .65, .46, .50, .37)
mean(sample2)
sd(sample2)
qqnorm(sample2)
qqline(sample2)
mean(sample2)
sd(sample2)
qt(.975, 4)
pt(-2.1416, 4, .6)
pt(-2.1416, 4)
library(tidymodels)
library(tidyverse)
#install.packages('tidymodels')
#install.packages('tidyverse')
library(tidymodels)
library(vroom)
install.packages('DataExplorer')
library(patchwork)
data1 <- vroom("train.csv") # grab training data
setwd("~/byu_fall_2023/Stat_348/STAT348/KaggleBikeShare/data")
data1 <- vroom("train.csv") # grab training data
view(data1)
data1$weather[data1$weather == 4] <- 3 # change value of 4 for Weather to 3
# unique(data1$weather)
#str(data1)
factor_cols <- c(2:5)
data1 <- data1 %>%
mutate(across(factor_cols, as.factor)) # convert factor variables
# str(data1)
data1 <- data1 %>%
select(-registered, -casual) # drop registered and casual
view(data1)
rFormula <- count ~ .
my_recipe <- recipe(rFormula, data = data1) %>% # set model formula and dataset
step_time(datetime, features = 'hour') %>% # get hours
step_dummy(all_nominal_predictors()) # get dummy variables
prepped_recipe <- prep(my_recipe) # preprocessing new data
baked_data1 <- bake(prepped_recipe, new_data = data1)
factor_cols2 <- c(8:14)
baked_data1 <- baked_data1 %>%
mutate(across(factor_cols2, as.factor)) # Convert dummy variables into factors
view(baked_data1[1:10,])
my_mod <- linear_reg()
my_mod <- linear_reg() %>% # Type of Model
set_engine("lm")
bike_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_mod) %>%
fit(data = data1) # Fit the workflow
data_test <- vroom("test.csv") # grab testing data
data_test
bike_predictions <- predict(bike_workflow,
new_data = data_test)
data1 <- vroom("train.csv") # grab training data
view(data1)
data1$weather[data1$weather == 4] <- 3 # change value of 4 for Weather to 3
# unique(data1$weather)
#str(data1)
factor_cols <- c(2:5)
data1 <- data1 %>%
mutate(across(factor_cols, as.factor)) # convert factor variables
# str(data1)
data1 <- data1 %>%
select(-registered, -casual) # drop registered and casual
view(data1)
rFormula <- count ~ .
my_recipe <- recipe(rFormula, data = data1) %>% # set model formula and dataset
step_time(datetime, features = 'hour') %>% # get hours
step_dummy(all_nominal_predictors()) # get dummy variables
prepped_recipe <- prep(my_recipe) # preprocessing new data
baked_data1 <- bake(prepped_recipe, new_data = data1)
# factor_cols2 <- c(8:14)
# baked_data1 <- baked_data1 %>%
#   mutate(across(factor_cols2, as.factor)) # Convert dummy variables into factors
view(baked_data1[1:10,])
my_mod <- linear_reg() %>% # Type of Model
set_engine("lm") # R function to use
bike_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_mod) %>%
fit(data = data1) # Fit the workflow
data_test <- vroom("test.csv") # grab testing data
bike_predictions <- predict(bike_workflow,
new_data = data_test)
rlang::last_trace()
data1 <- vroom("train.csv") # grab training data
view(data1)
data1$weather[data1$weather == 4] <- 3 # change value of 4 for Weather to 3
# unique(data1$weather)
#str(data1)
factor_cols <- c(2:5)
# data1 <- data1 %>%
#   mutate(across(factor_cols, as.factor)) # convert factor variables
# str(data1)
data1 <- data1 %>%
select(-registered, -casual) # drop registered and casual
view(data1)
rFormula <- count ~ .
my_recipe <- recipe(rFormula, data = data1) %>% # set model formula and dataset
step_mutate(across(factor_cols, as.factor)) %>%
step_time(datetime, features = 'hour') %>% # get hours
step_dummy(all_nominal_predictors()) # get dummy variables
prepped_recipe <- prep(my_recipe) # preprocessing new data
baked_data1 <- bake(prepped_recipe, new_data = data1)
# factor_cols2 <- c(8:14)
# baked_data1 <- baked_data1 %>%
#   mutate(across(factor_cols2, as.factor)) # Convert dummy variables into factors
view(baked_data1[1:10,])
my_mod <- linear_reg() %>% # Type of Model
set_engine("lm") # R function to use
bike_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_mod) %>%
fit(data = data1) # Fit the workflow
data_test <- vroom("test.csv") # grab testing data
bike_predictions <- predict(bike_workflow,
new_data = data_test)
bike_predictions
bike_predictions
length(bike_predictions)
typeof(bike_predictions)
i <- 0
length(bike_predictions)
view(bike_predictions)
ifelse(bike_predictions$.pred < 0, 0, bike_predictions$.pred)
bike_predictions <- ifelse(bike_predictions$.pred < 0, 0, bike_predictions$.pred)
out_file <- tempfile(fileext = "csv")
vroom_write(bike_predictions, out_file, ",")
vroom_write(bike_predictions, "bike_predictions.csv")
out_file <- tempfile(fileext = "csv")
vroom_write(bike_predictions, out_file, ",")
vroom_write(bike_predictions, "bike_predictions.csv", delim = ",")
bike_predictions
data1 <- vroom("train.csv") # grab training data
view(data1)
data1$weather[data1$weather == 4] <- 3 # change value of 4 for Weather to 3
# unique(data1$weather)
#str(data1)
factor_cols <- c(2:5)
# data1 <- data1 %>%
#   mutate(across(factor_cols, as.factor)) # convert factor variables
# str(data1)
data1 <- data1 %>%
select(-registered, -casual) # drop registered and casual
view(data1)
rFormula <- count ~ .
my_recipe <- recipe(rFormula, data = data1) %>% # set model formula and dataset
step_mutate(across(factor_cols, as.factor)) %>%
step_time(datetime, features = 'hour') %>% # get hours
step_dummy(all_nominal_predictors()) # get dummy variables
prepped_recipe <- prep(my_recipe) # preprocessing new data
baked_data1 <- bake(prepped_recipe, new_data = data1)
# factor_cols2 <- c(8:14)
# baked_data1 <- baked_data1 %>%
#   mutate(across(factor_cols2, as.factor)) # Convert dummy variables into factors
view(baked_data1[1:10,])
my_mod <- linear_reg() %>% # Type of Model
set_engine("lm") # R function to use
bike_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_mod) %>%
fit(data = data1) # Fit the workflow
data_test <- vroom("test.csv") # grab testing data
bike_predictions <- predict(bike_workflow,
new_data = data_test)
bike_predictions <- bike_predictions %>%
mutate(ifelse(bike_predictions$.pred < 0, 0, bike_predictions$.pred)) %>%
select(datetime, count)
bike_predictions <- bike_predictions %>%
mutate(ifelse(bike_predictions$.pred < 0, 0, bike_predictions$.pred))
bike_predictions <- cbind(bike_predictions, data1$datetime, data1$count)
nrow(data1)
nrow(bike_predictions)
bike_predictions <- predict(bike_workflow,
new_data = data_test)
bike_predictions <- bike_predictions %>%
mutate(ifelse(bike_predictions$.pred < 0, 0, bike_predictions$.pred))
bike_predictions
bike_predictions <- bike_predictions %>%
mutate(.pred = ifelse(bike_predictions$.pred < 0, 0, bike_predictions$.pred))
bike_predictions
bike_predictions <- predict(bike_workflow,
new_data = data_test)
bike_predictions <- bike_predictions %>%
mutate(.pred = ifelse(bike_predictions$.pred < 0, 0, bike_predictions$.pred))
bike_predictions
bike_predictions <- cbind(bike_predictions, data_test$datetime)
bike_predictions
bike_predictions
bike_predictions <- predict(bike_workflow,
new_data = data_test)
bike_predictions <- bike_predictions %>%
mutate(.pred = ifelse(bike_predictions$.pred < 0, 0, bike_predictions$.pred))
bike_predictions <- cbind(data_test$datetime, bike_predictions)
bike_predictions
data_test <- vroom("test.csv") # grab testing data
data_test$weather <- data_test$weather[data1$weather == 4] <- 3
data_test$weather <- data_test$weather[data_test$weather == 4] <- 3
bike_predictions <- predict(bike_workflow,
new_data = data_test)
bike_predictions <- bike_predictions %>%
mutate(.pred = ifelse(bike_predictions$.pred < 0, 0, bike_predictions$.pred))
bike_predictions <- cbind(data_test$datetime, bike_predictions)
bike_predictions
bike_predictions <- cbind(data_test$datetime, bike_predictions) %>%
mutate(colnames(bike_predictions)[1] = "datetime") %>%
mutate(colnames(bike_predictions)[2] = "count")
bike_predictions
bike_predictions <- colnames(bike_predictions)[1] = "datetime"
colnames(bike_predictions)[1]
colnames(bike_predictions)[1] = "datetime"
colnames(bike_predictions)[2] = "count"
bike_predictions
bike_predictions <- bike_predictions %>%
mutate(count = ifelse(bike_predictions$count == 0, as.integer(bike_predictions$count), bike_predictions$count))
bike_predictions
vroom_write(bike_predictions, "bike_predictions.csv", delim = ",")
bike_predictions$datetime <- as.character(format(bike_predictions$datetime))
bike_predictions$datetime
vroom_write(bike_predictions, "bike_predictions.csv", delim = ",")
gc()
