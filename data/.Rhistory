geom_boxplot(mapping = aes(x = Group, y = LifeExp)) +
theme(aspect.ratio = 1) +
labs(title = 'Groups vs Life Expectancy Box Plot',
y = 'Life Expectancy (Years)')
ggplot(data = life) +
geom_point(mapping = aes(x = PPGDP,
y = LifeExp,
color = Group)) +
theme(aspect.ratio = 1) +
labs(title = 'PPGDP vs Life Expectancy Scatterplot (color by Group)',
x = 'Per Person GDP (Log Scale)',
y = 'Life Expectancy (Years)')
life$africaYes <- ifelse(life$africa == 'Yes', 1, 0)
life$africaGroup <- ifelse(life$Group == 'africa', 1, 0)
#life$africaNo <- ifelse(life$africa == 'No', 1, 0)
life$oecdGroup <- ifelse(life$Group == 'oecd', 1, 0)
#life$oecdNo <- ifelse(life$oecd == "No", 1, 0)
life_lm_overparm <- lm(Group ~ other +
africaGroup +
oecdGroup,
data = life)
life_lm_overparm <- lm(life ~ Group +
africaGroup +
oecdGroup,
data = life)
life_lm_overparm <- lm(Group ~ other +
africaGroup +
oecdGroup,
data = life)
life_lm_overparm <- lm(life ~ PPGDP +
africaGroup +
oecdGroup,
data = life)
life_lm_overparm <- lm(LifeExp ~ PPGDP +
africaGroup +
oecdGroup,
data = life)
summary(life_lm_overparm)
confint(life_lm_overparm, level = 0.95)
anova(life_lm_overparm, LifeExp ~ Group)
life_lm_overparm2 <- lm(LifeExp ~ PPGDP,
data = life)
anova(life_lm_overparm, life_lm_overparm2)
predict(life_lm_overparm,
newdata = data.frame(PPGDP = 9.5,
oecdGroup = 1,
africaGroup = 0),
interval = "prediction",
level = 0.95)
ggplot(life) +
geom_point(mapping = aes(x = PPGDP,
y = LifeExp,
color = Group)) +
geom_line(mapping = aes(x = PPGDP,
y = predict(life_lm_overparm),
color = Group)) +
theme(aspect.ratio = 1)
ggplot(life) +
geom_point(mapping = aes(x = PPGDP,
y = LifeExp,
color = Group)) +
geom_line(mapping = aes(x = PPGDP,
y = predict(life_lm_overparm),
color = Group)) +
theme(aspect.ratio = 1) +
labs(title = 'PPGDP vs Life Expectancy Scatterplot (color by Group)',
x = 'Per Person GDP (Log Scale)',
y = 'Life Expectancy (Years)')
life_lm_inter <- lm(LifeExp ~ PPGDP +
africaGroup +
oecdGroup +
PPGDP:Group,
data = salary)
life_lm_inter <- lm(LifeExp ~ PPGDP +
africaGroup +
oecdGroup +
PPGDP:Group,
data = life)
summary(life_lm_inter)
life_lm_inter <- lm(LifeExp ~ PPGDP +
africaGroup +
oecdGroup +
PPGDP:africaGroup +
PPGDP:oecdGroup,
data = life)
summary(life_lm_inter)
anova(life_lm_overparm, life_lm_inter)
ggplot(life) +
geom_point(mapping = aes(x = PPGDP,
y = LifeExp,
color = Group)) +
geom_line(mapping = aes(x = PPGDP,
y = predict(life_lm_inter),
color = Group)) +
theme(aspect.ratio = 1) +
labs(title = 'PPGDP vs Life Expectancy Scatterplot (color by Group)',
x = 'Per Person GDP (Log Scale)',
y = 'Life Expectancy (Years)')
pbinom(54, 4, lower.tail = TRUE)
pnorm(q = 54, mean = 53, sd = .5, lower.tail = TRUE)
pnorm(q = 53, mean = 53, sd = .5, lower.tail = TRUE)
pnorm(q = 54, mean = 53, sd = .5, lower.tail = TRUE) - pnorm(q = 53, mean = 53, sd = .5, lower.tail = TRUE)
n_list <- c(1:25)
ideal_prob <- function(n_list) {
for(i in n_list) {
print(n_list[i])
}
}
ideal_prob()
ideal_prob()
ideal_prob <- function(list) {
for(i in n_list) {
print(list[i])
}
}
ideal_prob(n_list)
ideal_prob <- function(list) {
for(i in n_list) {
sd_i <- sqrt(1/n_list[i])
p_i <- pnorm(q = 54, mean = 53, sd = sd_i, lower.tail = TRUE)
print(p_i)
}
}
ideal_prob(n_list)
ideal_prob <- function(list) {
for(i in n_list) {
sd_i <- sqrt(1/n_list[i])
p_i <- pnorm(q = 54, mean = 53, sd = sd_i, lower.tail = TRUE)
print(c(n_list[i],p_i))
}
}
ideal_prob(n_list)
ideal_prob <- function(list) {
for(i in n_list) {
sd_i <- sqrt(1/n_list[i])
p_i <- pnorm(q = 54, mean = 53, sd = sd_i, lower.tail = TRUE)
print(c(lapply(n_list[i]),p_i))
}
}
ideal_prob(n_list)
ideal_prob <- function(list) {
for(i in n_list) {
sd_i <- sqrt(1/n_list[i])
p_i <- pnorm(q = 54, mean = 53, sd = sd_i, lower.tail = TRUE)
print(c(lapply(n_list[i], as.integer),p_i))
}
}
ideal_prob(n_list)
ideal_prob <- function(list) {
for(i in n_list) {
sd_i <- sqrt(1/n_list[i])
p_i <- pnorm(q = 54, mean = 53, sd = sd_i, lower.tail = TRUE)
print(p_i)
}
}
ideal_prob(n_list)
pnorm(q = 500, mean = 390, sd = 14.6969, lower.tail = TRUE)
pbern(x, prob = 0.6)
phat <- vector(0:n)/n
p = .6
n = 3
calc_binomzn <- function(p, n) {
}
calc_binomzn(p,n)
calc_binomzn <- function(p, n) {
phat <- vector(0:n)/n
zn <- (phat - p) / (sqrt((p(1-p))/n))
Fbin <- pbinom(n*p + sqrt(n*p*(1-p))*zn, n, p)
return(list(zn = zn, Fbin = Fbin))
}
n3
n3 <- calc_binomzn(.6, 3)
calc_binomzn <- function(p, n) {
phat <- c(0:n)/n
zn <- (phat - p) / (sqrt((p(1-p))/n))
Fbin <- pbinom(n*p + sqrt(n*p*(1-p))*zn, n, p)
return(list(zn = zn, Fbin = Fbin))
}
n3 <- calc_binomzn(.6, 3)
calc_binomzn <- function(p, n) {
phat <- c(0:n)/n
zn <- (phat - p) / (sqrt((p*(1-p))/n))
Fbin <- pbinom(n*p + sqrt(n*p*(1-p))*zn, n, p)
return(list(zn = zn, Fbin = Fbin))
}
n3 <- calc_binomzn(.6, 3)
n15 <- calc_binomzn(.6, 15)
n30 <- calc_binomzn(.6, 30)
n3
n15
n30
plot(n3$zn, n3$Fbin)
plot(n3$zn, n3$Fbin, type = 's')
plot(n3$zn, n3$Fbin, type = 's')
plot(n3$zn, n3$Fbin, type = 's')
plot(n3$zn, n3$Fbin, type = 's')
points(n15$zn, n15$Fbin, type = 's')
points(n30$zn, n30$Fbin, type = 's')
plot(n3$zn, n3$Fbin, type = 's')
points(n15$zn, n15$Fbin, type = 's')
points(n30$zn, n30$Fbin, type = 's')
curve(pnorm, from = -2, to = 1.5)
plot(n3$zn, n3$Fbin, type = 's')
points(n15$zn, n15$Fbin, type = 's')
points(n30$zn, n30$Fbin, type = 's')
curve(pnorm, from = -2, to = 1.5)
plot(n3$zn, n3$Fbin, type = 's')
points(n15$zn, n15$Fbin, type = 's')
points(n30$zn, n30$Fbin, type = 's')
points(curve(pnorm, from = -2, to = 1.5))
lines(pnorm, from = -2, to = 1.5)
lines(x, type = 's')
x_n <- seq(from = -3, to = 3)
pnorm(x_n, 0, 1)
x_n1 <- pnorm(x_n, 0, 1)
lines(x_n1, type = 's')
lines(x_n1, y = NULL, type = 's')
lines(x_n, x_n1, type = 's')
plot(n3$zn, n3$Fbin, type = 's')
x_n <- seq(-2:2)
x_n
x_n <- seq(-200:200)/50
x_n
points(x_n, pnorm(x_n, 0, 1), type = 's')
plot(n3$zn, n3$Fbin, type = 's')
points(n15$zn, n15$Fbin, type = 's')
points(n30$zn, n30$Fbin, type = 's')
points(x_n, pnorm(x_n, 0, 1), type = 's')
x_n <- seq(-200:200)
x_n
x_n <- seq(-2, 2, 0.001)
x_n
plot(n3$zn, n3$Fbin, type = 's')
points(n15$zn, n15$Fbin, type = 's')
points(n30$zn, n30$Fbin, type = 's')
points(x_n, pnorm(x_n, 0, 1), type = 's')
# load packages here
library(tidyverse)
# read in data
df <- read_csv('state_of_utah.csv')
head(df)
df['81-90'] <- df %>%
mutate(sum = rowSums(across(c(`1981`, `1982`, `1983`, `1984`, `1985`, `1986`, `1987`, `1988`, `1989`, `1990`))))
df %>%
mutate(sum = rowSums(across(c(`1981`, `1982`, `1983`, `1984`, `1985`, `1986`, `1987`, `1988`, `1989`, `1990`))))
df[,'81-90'] <- df[,54]
df[,54]
df[54]
df[, 54]
df[, 12]
df
df[,'81-90'] <- df %>%
mutate(sum = rowSums(across(c(`1981`, `1982`, `1983`, `1984`, `1985`, `1986`, `1987`, `1988`, `1989`, `1990`))))
df1 <- df %>%
mutate(sum = rowSums(across(c(`1981`, `1982`, `1983`, `1984`, `1985`, `1986`, `1987`, `1988`, `1989`, `1990`))))
df[,'81-90'] <- df1[, 54]
df
df2 <- df %>%
mutate(sum = rowSums(across(c(`1991`, `1992`, `1993`, `1994`, `1995`, `1996`, `1997`, `1998`, `1999`, `2000`))))
df[, '91-2000'] <- df2[, 54]
df
# load packages here
library(tidyverse)
# read in data
df <- read_csv('state_of_utah.csv')
# head(df)
df1 <- df %>%
mutate(sum = rowSums(across(c(`1981`, `1982`, `1983`, `1984`, `1985`, `1986`, `1987`, `1988`, `1989`, `1990`))))
df[,'81-90'] <- df1[, 54]
df2 <- df %>%
mutate(sum = rowSums(across(c(`1991`, `1992`, `1993`, `1994`, `1995`, `1996`, `1997`, `1998`, `1999`, `2000`))))
df[, '91-2000'] <- df2[, 54]
df3 <- df %>%
mutate(sum = rowSums(across(c(`2001`, `2002`, `2003`, `2004`, `2005`, `2006`, `2007`, `2008`, `2009`, `2010`))))
df[, '01-2010'] <- df3[, 54]
df4 <- df %>%
mutate(sum = rowSums(across(c(`2011`, `2012`, `2013`, `2014`, `2015`, `2016`, `2017`, `2018`, `2019`, `2020`))))
df[, '11-2020'] <- df2[, 54]
head(df)
# 1a
#define range
p = seq(0, 1, length=100)
#create plot of Beta distribution with shape parameters
plot(p, dbeta(p, 6, 4), type='l')
# 1d
qbeta(.025, 83, 27)
qbeta(.975, 83, 27)
#create plot of Beta distribution with shape parameters
plot1 <- plot(p, dbeta(p, 6, 4), type='l')
#create plot of Beta distribution with shape parameters
plot1 <- plot(p, dbeta(p, 6, 4), type='l')
# 1e
plot1
# 1e
plot(p, dbeta(p, 83, 27), type='l')
# 1e
plot(p, dbeta(p, 83, 27), type='l')
plot(p, dbeta(p, 83, 27), type='l')
abline(v = .7545)
abline(v = 0.670348, col="red", lwd=3, lty=2)
abline(v = 0.82998, col="red", lwd=3, lty=2)
# 2a
plot(p, dnorm(p, 15, sqrt(2.5)), type = 'l')
# 2a
p2 = seq(10, 20, length = 100)
plot(p2, dnorm(p, 15, sqrt(2.5)), type = 'l')
p2
plot(p2, dnorm(p, 15, sqrt(2.5)), type = 'l')
plot(p2, dnorm(p2, 15, sqrt(2.5)), type = 'l')
# 2d
qnorm(.025, 14.9358, 0.9682)
qnorm(.975, 14.9358, 0.9682)
plot(p2, dnorm(p2, 14.9358, 0.9682), type='l')
abline(v = .14.9358)
abline(v = 13.03816, col="red", lwd=3, lty=2)
abline(v = 16.83344, col="red", lwd=3, lty=2)
abline(v = .14.9358)
plot(p2, dnorm(p2, 14.9358, 0.9682), type='l')
abline(v = 14.9358)
abline(v = 13.03816, col="red", lwd=3, lty=2)
abline(v = 16.83344, col="red", lwd=3, lty=2)
# Question 1
t.test(x, conf.level = 0.88)
# Question 1
t.test(1584, conf.level = 0.99)
# Question 1
qt(.99, 19)
# Question 1
qt(.995, 19)
# Question 2
c(25.2,21.3,22.8,17,29.8,21,25.5,16,20.9,19.5)
# Question 2
sample1 <- c(25.2,21.3,22.8,17,29.8,21,25.5,16,20.9,19.5)
mean(sample1)
sd(sample1)
qt(.975, 9)
# Question 3
sample2 <- c(.53, .65, .46, .50, .37)
# L: Residuals vs. Fitted Values Plot
sample2_residvfit <- autoplot(sample2, which = 1, ncol = 1, nrow = 1) +
theme(aspect.ratio = 1)
library(tidyverse)
library(ggfortify)
# Check Normality Assumption
# Normal Probability Plot
#   "qq plot"
sample2_qq <- autoplot(sample2, which = 2, ncol = 1, nrow = 1) +
theme(aspect.ratio = 1)
sample2_qq
qqnorm(sample2)
qqnorm(sample2)
qqline(sample2)
qqline(sample2)
qqnorm(sample2)
qqnorm(sample2)
qqnorm(sample2)
qqline(sample2)
# Question 4
sample2 <- c(.53, .65, .46, .50, .37)
mean(sample2)
sd(sample2)
qqnorm(sample2)
qqline(sample2)
mean(sample2)
sd(sample2)
qt(.975, 4)
pt(-2.1416, 4, .6)
pt(-2.1416, 4)
find_joint_p1 <- function(x, y){
solution1 <- ((y)^(x)) / (fact(x) * (1 + y + ((y^2)/2) + ((y^3)/6) + ((y^4)/24)))
}
find_joint_p1(1, 0.5)
find_joint_p1 <- function(x, y){
solution1 <- ((y)^(x)) / (factorial(x) * (1 + y + ((y^2)/2) + ((y^3)/6) + ((y^4)/24)))
}
find_joint_p1(1, 0.5)
print(find_joint_p1(1, 0.5))
x1 <- find_joint_p1(1, 0.5)
x1/10
x1 <- find_joint_p1(2, 0.5)
x1/10
x1 <- find_joint_p1(3, 0.5)
x1/10
x1 <- find_joint_p1(4, 0.5)
x1/10
x1 <- find_joint_p1(0, 1)
x1*(2/10)
x1 <- find_joint_p1(1, 1)
x1*(2/10)
x1 <- find_joint_p1(2, 1)
x1*(2/10)
x1 <- find_joint_p1(3, 1)
x1*(2/10)
x1 <- find_joint_p1(4, 1)
x1*(2/10)
x1 <- find_joint_p1(0, 2)
x1*(7/10)
x1 <- find_joint_p1(1, 2)
x1*(7/10)
x1 <- find_joint_p1(2, 2)
x1*(7/10)
x1 <- find_joint_p1(3, 2)
x1*(7/10)
x1 <- find_joint_p1(4, 2)
x1*(7/10)
find_joint_p1 <- function(x, y){
solution1 <- ((y)^(x)) / (factorial(x) * (1 + y + ((y^2)/2) + ((y^3)/6) + ((y^4)/24)))
}
x1 <- find_joint_p1(1, 0.5)
x1
x1 <- find_joint_p1(2, 0.5)
x1
x1 <- find_joint_p1(3, 0.5)
x1
x1 <- find_joint_p1(4, 0.5)
x1
x1*4
x1 <- find_joint_p1(3, 0.5)
x1
x1 <- find_joint_p1(2, 0.5)
x1
x1*2
x1 <- find_joint_p1(3, 0.5)
x1
x1*3
0.03791469 + 0.1516588 + 0.006319115 + 0.3033175
find_joint_p1 <- function(x, y){
solution1 <- ((y)^(x)) / (factorial(x) * (1 + y + ((y^2)/2) + ((y^3)/6) + ((y^4)/24)))
}
################################################################################
# Regression Tree
install.packages("rpart")
library(tidymodels)
my_mod <- decision_tree(tree_depth = tune(),
cost_complexity = tune(),
min_n = tune()) %>%
set_engine("rpart") %>%
set_mode("regression")
my_mod
data_train <- vroom("train.csv") # grab training data
data_train <- data_train %>%
select(-casual, - registered) # drop casual and registered variables
setwd("~/byu_fall_2023/Stat_348/STAT348/KaggleBikeShare/data")
data_train <- vroom("train.csv") # grab training data
library(tidyverse)
library(tidymodels)
install.packages("glmnet")
library(glmnet)
library(vroom)
data_train <- vroom("train.csv") # grab training data
data_train <- data_train %>%
select(-casual, - registered) # drop casual and registered variables
log_train_set <- data_train %>%
mutate(count=log(count))
bike_recipe <- recipe(count ~ ., data=log_train_set) %>%
step_mutate(weather=ifelse(weather==4, 3, weather)) %>% #Change weather 4 to 3
step_mutate(weather=factor(weather, levels=1:3, labels=c("Sunny", "Mist", "Rain"))) %>% # change weather as factor INSIDE RECIPE
step_mutate(season=factor(season, levels=1:4, labels=c("Spring", "Summer", "Fall", "Winter"))) %>% # convert season to factor with levels
step_mutate(holiday=factor(holiday, levels=c(0,1), labels=c("No", "Yes"))) %>% # convert holiday to factor
step_time(datetime, features="hour") %>% # this hourly variable will replace datetime
step_rm(datetime)
prepped_recipe <- prep(bike_recipe) # preprocessing new data
baked_data1 <- bake(prepped_recipe, new_data = log_train_set)
## Set Workflow
preg_wf <- workflow() %>%
add_recipe(bike_recipe) %>%
add_model(my_mod)
## Grid of values to tune over
tuning_grid <- grid_regular(tree_depth(),
cost_complexity(),
min_n(),
levels = 3) ## L^2 total tuning possibilities
## Split data for CV
folds <- vfold_cv(data_train, v = 10, repeats=1) # k-fold CV
## Run the CV1
CV_results <- preg_wf %>%
tune_grid(resamples=folds,
grid=tuning_grid,
metrics=metric_set(rmse, mae, rsq)) #Or leave metrics NULL
## Plot Results (example)
collect_metrics(CV_results) %>% # Gathers metrics into DF
filter(.metric=="rmse") %>%
ggplot(data=., aes(x=penalty, y=mean, color=factor(mixture))) +
geom_line()
## Find Best Tuning Parameters13
bestTune <- CV_results %>%
select_best("rmse")
bestTune
## Finalize the Workflow & fit it1
final_wf <- preg_wf %>%
finalize_workflow(bestTune) %>%
fit(data=log_train_set)
data_test <- vroom("test.csv") # input test data
final_log_lin_preds <- predict(final_wf, new_data = data_test) %>% #This predicts log(count)
mutate(.pred=exp(.pred)) %>% # Back-transform the log to original scale
bind_cols(., data_test) %>% #Bind predictions with test data
select(datetime, .pred) %>% #Just keep datetime and predictions
rename(count=.pred) %>% #rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% #pointwise max of (0, prediction)
mutate(datetime=as.character(format(datetime))) #needed for right format to Kaggle
vroom_write(final_log_lin_preds, "bike_predictions_penreg_cv.csv", delim = ",")
vroom_write(final_log_lin_preds, "bike_predictions_reg_tree.csv", delim = ",")
## Plot Results (example)
collect_metrics(CV_results) %>% # Gathers metrics into DF
filter(.metric=="rmse") %>%
ggplot(data=., aes(x=penalty, y=mean, color=factor(mixture))) +
geom_line()
## Plot Results (example)
collect_metrics(CV_results) %>% # Gathers metrics into DF
filter(.metric=="rmse") %>%
ggplot(data=., aes(x=tree_depth, y=mean, color=factor(mixture))) +
geom_line()
